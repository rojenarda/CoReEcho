{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2Qhvrq74QG2l"},"outputs":[],"source":["# Local\n","import_path = '/Users/sesena/Documents/itu/ml/echo/coreecho/CoReEcho/'\n","# Add path for importing\n","import sys\n","\n","sys.path.append(import_path)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3832,"status":"ok","timestamp":1732701822761,"user":{"displayName":"Rojen Arda Şeşen","userId":"09468982930633953911"},"user_tz":-180},"id":"rJ_voKjITY1I","outputId":"490fcce8-c120-484c-968e-13e76e615c50"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'CoReEcho'...\n","remote: Enumerating objects: 51, done.\u001b[K\n","remote: Counting objects: 100% (51/51), done.\u001b[K\n","remote: Compressing objects: 100% (38/38), done.\u001b[K\n","remote: Total 51 (delta 17), reused 47 (delta 13), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (51/51), 1.76 MiB | 1.60 MiB/s, done.\n","Resolving deltas: 100% (17/17), done.\n"]}],"source":["!git clone https://github.com/rojenarda/CoReEcho\n","!mv CoReEcho/coreecho coreecho\n","!mv CoReEcho/requirements.txt requirements.txt\n","!mv CoReEcho/test_start_indexes.pkl test_start_indexes.pkl\n","!rm -rf CoReEcho"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"executionInfo":{"elapsed":289225,"status":"ok","timestamp":1732702111982,"user":{"displayName":"Rojen Arda Şeşen","userId":"09468982930633953911"},"user_tz":-180},"id":"3qlxzlZHN2Ke","outputId":"61262c83-839a-4ec1-e3db-983983e712c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting albumentations==1.2.1\n","  Downloading albumentations-1.2.1-py3-none-any.whl.metadata (33 kB)\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.2.1) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from albumentations==1.2.1) (1.13.1)\n","Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.2.1) (0.24.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.2.1) (6.0.2)\n","Collecting qudida>=0.0.4 (from albumentations==1.2.1)\n","  Downloading qudida-0.0.4-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.2.1) (4.10.0.84)\n","Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.2.1) (1.5.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.2.1) (4.12.2)\n","Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (3.4.2)\n","Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (11.0.0)\n","Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (2.36.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (2024.9.20)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (24.2)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.2.1) (0.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.2.1) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.2.1) (3.5.0)\n","Downloading albumentations-1.2.1-py3-none-any.whl (116 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.7/116.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n","Installing collected packages: qudida, albumentations\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 1.4.20\n","    Uninstalling albumentations-1.4.20:\n","      Successfully uninstalled albumentations-1.4.20\n","Successfully installed albumentations-1.2.1 qudida-0.0.4\n","Collecting matplotlib==3.7.3\n","  Downloading matplotlib-3.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (1.4.7)\n","Requirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (24.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.3) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.3) (1.16.0)\n","Downloading matplotlib-3.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: matplotlib\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.8.0\n","    Uninstalling matplotlib-3.8.0:\n","      Successfully uninstalled matplotlib-3.8.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","plotnine 0.14.1 requires matplotlib>=3.8.0, but you have matplotlib 3.7.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed matplotlib-3.7.3\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"b2eb9c7ee8064eccaeb147fdf316f9d1","pip_warning":{"packages":["matplotlib","mpl_toolkits"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Collecting numpy==1.22.4\n","  Downloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n","Downloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/16.8 MB\u001b[0m \u001b[31m177.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m12.3/16.8 MB\u001b[0m \u001b[31m184.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m197.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m197.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.22.4 which is incompatible.\n","arviz 0.20.0 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n","astropy 6.1.6 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n","bigframes 1.27.0 requires numpy>=1.24.0, but you have numpy 1.22.4 which is incompatible.\n","chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.22.4 which is incompatible.\n","contourpy 1.3.1 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n","cudf-cu12 24.10.1 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n","ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.22.4 which is incompatible.\n","jax 0.4.33 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n","jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n","mizani 0.13.0 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n","numexpr 2.10.1 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n","nx-cugraph-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n","pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n","plotnine 0.14.1 requires matplotlib>=3.8.0, but you have matplotlib 3.7.3 which is incompatible.\n","plotnine 0.14.1 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n","pylibraft-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n","rmm-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n","scikit-image 0.24.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n","tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.4 which is incompatible.\n","xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n","xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.22.4\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"3235d39a32664b5baf254f83f73c4f3f","pip_warning":{"packages":["numpy"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Collecting pandas==1.4.3\n","  Downloading pandas-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.4.3) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.4.3) (2024.2)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.4.3) (1.22.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.4.3) (1.16.0)\n","Downloading pandas-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pandas\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.2\n","    Uninstalling pandas-2.2.2:\n","      Successfully uninstalled pandas-2.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","arviz 0.20.0 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n","arviz 0.20.0 requires pandas>=1.5.0, but you have pandas 1.4.3 which is incompatible.\n","bigframes 1.27.0 requires numpy>=1.24.0, but you have numpy 1.22.4 which is incompatible.\n","bigframes 1.27.0 requires pandas>=1.5.3, but you have pandas 1.4.3 which is incompatible.\n","cudf-cu12 24.10.1 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n","cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.4.3 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.4.3 which is incompatible.\n","ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.22.4 which is incompatible.\n","ibis-framework 9.2.0 requires pandas<3,>=1.5.3, but you have pandas 1.4.3 which is incompatible.\n","mizani 0.13.0 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n","mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.4.3 which is incompatible.\n","plotnine 0.14.1 requires matplotlib>=3.8.0, but you have matplotlib 3.7.3 which is incompatible.\n","plotnine 0.14.1 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n","plotnine 0.14.1 requires pandas>=2.2.0, but you have pandas 1.4.3 which is incompatible.\n","xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n","xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.4.3 which is incompatible.\n","xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pandas-1.4.3\n","Collecting pytorch_lightning==1.9.5\n","  Downloading pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.9.5) (1.22.4)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.9.5) (2.5.1+cu121)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.9.5) (4.66.6)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.9.5) (6.0.2)\n","Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning==1.9.5) (2024.10.0)\n","Collecting torchmetrics>=0.7.0 (from pytorch_lightning==1.9.5)\n","  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.9.5) (24.2)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.9.5) (4.12.2)\n","Collecting lightning-utilities>=0.6.0.post0 (from pytorch_lightning==1.9.5)\n","  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning==1.9.5) (3.11.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.6.0.post0->pytorch_lightning==1.9.5) (75.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch_lightning==1.9.5) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch_lightning==1.9.5) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch_lightning==1.9.5) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch_lightning==1.9.5) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->pytorch_lightning==1.9.5) (1.3.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.5) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.5) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.5) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.5) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.5) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.5) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.5) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.5) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->pytorch_lightning==1.9.5) (3.0.2)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.5) (3.10)\n","Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n","Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n","Successfully installed lightning-utilities-0.11.9 pytorch_lightning-1.9.5 torchmetrics-1.6.0\n","Collecting pyyaml==6.0\n","  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.0 kB)\n","Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyyaml\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0.2\n","    Uninstalling PyYAML-6.0.2:\n","      Successfully uninstalled PyYAML-6.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","astropy 6.1.6 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pyyaml-6.0\n","Collecting scikit_image==0.19.3\n","  Downloading scikit_image-0.19.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scikit_image==0.19.3) (1.22.4)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit_image==0.19.3) (1.13.1)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit_image==0.19.3) (3.4.2)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_image==0.19.3) (11.0.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit_image==0.19.3) (2.36.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit_image==0.19.3) (2024.9.20)\n","Collecting PyWavelets>=1.1.1 (from scikit_image==0.19.3)\n","  Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit_image==0.19.3) (24.2)\n","Collecting numpy>=1.17.0 (from scikit_image==0.19.3)\n","  Downloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_image-0.19.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, PyWavelets, scikit_image\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.22.4\n","    Uninstalling numpy-1.22.4:\n","      Successfully uninstalled numpy-1.22.4\n","  Attempting uninstall: scikit_image\n","    Found existing installation: scikit-image 0.24.0\n","    Uninstalling scikit-image-0.24.0:\n","      Successfully uninstalled scikit-image-0.24.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","arviz 0.20.0 requires pandas>=1.5.0, but you have pandas 1.4.3 which is incompatible.\n","bigframes 1.27.0 requires pandas>=1.5.3, but you have pandas 1.4.3 which is incompatible.\n","cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.4.3 which is incompatible.\n","cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.1.3 which is incompatible.\n","gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.3 which is incompatible.\n","ibis-framework 9.2.0 requires pandas<3,>=1.5.3, but you have pandas 1.4.3 which is incompatible.\n","langchain 0.3.7 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.1.3 which is incompatible.\n","matplotlib 3.7.3 requires numpy<2,>=1.20, but you have numpy 2.1.3 which is incompatible.\n","mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.4.3 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.3 which is incompatible.\n","plotnine 0.14.1 requires matplotlib>=3.8.0, but you have matplotlib 3.7.3 which is incompatible.\n","plotnine 0.14.1 requires pandas>=2.2.0, but you have pandas 1.4.3 which is incompatible.\n","pytensor 2.26.3 requires numpy<2,>=1.17.0, but you have numpy 2.1.3 which is incompatible.\n","tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.3 which is incompatible.\n","thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.3 which is incompatible.\n","xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.4.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed PyWavelets-1.7.0 numpy-2.1.3 scikit_image-0.19.3\n","Collecting scikit_learn==1.3.2\n","  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Collecting numpy<2.0,>=1.17.3 (from scikit_learn==1.3.2)\n","  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.3.2) (1.13.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.3.2) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.3.2) (3.5.0)\n","Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, scikit_learn\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.1.3\n","    Uninstalling numpy-2.1.3:\n","      Successfully uninstalled numpy-2.1.3\n","  Attempting uninstall: scikit_learn\n","    Found existing installation: scikit-learn 1.5.2\n","    Uninstalling scikit-learn-1.5.2:\n","      Successfully uninstalled scikit-learn-1.5.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","arviz 0.20.0 requires pandas>=1.5.0, but you have pandas 1.4.3 which is incompatible.\n","bigframes 1.27.0 requires pandas>=1.5.3, but you have pandas 1.4.3 which is incompatible.\n","cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.4.3 which is incompatible.\n","ibis-framework 9.2.0 requires pandas<3,>=1.5.3, but you have pandas 1.4.3 which is incompatible.\n","mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.4.3 which is incompatible.\n","plotnine 0.14.1 requires matplotlib>=3.8.0, but you have matplotlib 3.7.3 which is incompatible.\n","plotnine 0.14.1 requires pandas>=2.2.0, but you have pandas 1.4.3 which is incompatible.\n","xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.4.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.4 scikit_learn-1.3.2\n","Collecting scipy==1.8.1\n","  Downloading scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n","Collecting numpy<1.25.0,>=1.17.3 (from scipy==1.8.1)\n","  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n","Downloading scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, scipy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.13.1\n","    Uninstalling scipy-1.13.1:\n","      Successfully uninstalled scipy-1.13.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","arviz 0.20.0 requires pandas>=1.5.0, but you have pandas 1.4.3 which is incompatible.\n","arviz 0.20.0 requires scipy>=1.9.0, but you have scipy 1.8.1 which is incompatible.\n","bigframes 1.27.0 requires pandas>=1.5.3, but you have pandas 1.4.3 which is incompatible.\n","cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.4.3 which is incompatible.\n","ibis-framework 9.2.0 requires pandas<3,>=1.5.3, but you have pandas 1.4.3 which is incompatible.\n","jax 0.4.33 requires scipy>=1.10, but you have scipy 1.8.1 which is incompatible.\n","jaxlib 0.4.33 requires scipy>=1.10, but you have scipy 1.8.1 which is incompatible.\n","mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.4.3 which is incompatible.\n","plotnine 0.14.1 requires matplotlib>=3.8.0, but you have matplotlib 3.7.3 which is incompatible.\n","plotnine 0.14.1 requires pandas>=2.2.0, but you have pandas 1.4.3 which is incompatible.\n","xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.4.3 which is incompatible.\n","xarray-einstats 0.8.0 requires scipy>=1.9, but you have scipy 1.8.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.24.4 scipy-1.8.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"669f6146ee5245fbae0839262a0f1c8b","pip_warning":{"packages":["numpy"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n","Collecting torch==1.12.1+cu116\n","  Downloading https://download.pytorch.org/whl/cu116/torch-1.12.1%2Bcu116-cp310-cp310-linux_x86_64.whl (1904.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 GB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1+cu116) (4.12.2)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cu121\n","    Uninstalling torch-2.5.1+cu121:\n","      Successfully uninstalled torch-2.5.1+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","peft 0.13.2 requires torch>=1.13.0, but you have torch 1.12.1+cu116 which is incompatible.\n","torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.12.1+cu116 which is incompatible.\n","torchmetrics 1.6.0 requires torch>=2.0.0, but you have torch 1.12.1+cu116 which is incompatible.\n","torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 1.12.1+cu116 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.12.1+cu116\n","Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n","Collecting torchvision==0.13.1+cu116\n","  Downloading https://download.pytorch.org/whl/cu116/torchvision-0.13.1%2Bcu116-cp310-cp310-linux_x86_64.whl (23.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1+cu116) (4.12.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1+cu116) (1.24.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1+cu116) (2.32.3)\n","Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1+cu116) (1.12.1+cu116)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1+cu116) (11.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1+cu116) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1+cu116) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1+cu116) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1+cu116) (2024.8.30)\n","Installing collected packages: torchvision\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.20.1+cu121\n","    Uninstalling torchvision-0.20.1+cu121:\n","      Successfully uninstalled torchvision-0.20.1+cu121\n","Successfully installed torchvision-0.13.1+cu116\n","Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n","Collecting torchaudio==0.12.1+cu116\n","  Downloading https://download.pytorch.org/whl/cu116/torchaudio-0.12.1%2Bcu116-cp310-cp310-linux_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio==0.12.1+cu116) (1.12.1+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1->torchaudio==0.12.1+cu116) (4.12.2)\n","Installing collected packages: torchaudio\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.5.1+cu121\n","    Uninstalling torchaudio-2.5.1+cu121:\n","      Successfully uninstalled torchaudio-2.5.1+cu121\n","Successfully installed torchaudio-0.12.1+cu116\n","Collecting opencv_contrib_python==4.4.0.46\n","  Downloading opencv-contrib-python-4.4.0.46.tar.gz (148.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.8/148.8 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","\n","\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n","\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","Collecting seaborn==0.13.0\n","  Downloading seaborn-0.13.0-py3-none-any.whl.metadata (5.3 kB)\n","Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.13.0) (1.24.4)\n","Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.13.0) (1.4.3)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.13.0) (3.7.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn==0.13.0) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn==0.13.0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn==0.13.0) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn==0.13.0) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn==0.13.0) (24.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn==0.13.0) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn==0.13.0) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn==0.13.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn==0.13.0) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn==0.13.0) (1.16.0)\n","Downloading seaborn-0.13.0-py3-none-any.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: seaborn\n","  Attempting uninstall: seaborn\n","    Found existing installation: seaborn 0.13.2\n","    Uninstalling seaborn-0.13.2:\n","      Successfully uninstalled seaborn-0.13.2\n","Successfully installed seaborn-0.13.0\n","Collecting timm==0.6.12\n","  Downloading timm-0.6.12-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm==0.6.12) (1.12.1+cu116)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.6.12) (0.13.1+cu116)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.6.12) (6.0)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.6.12) (0.26.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.6.12) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.6.12) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.6.12) (2024.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.6.12) (24.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.6.12) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.6.12) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.6.12) (1.24.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.6.12) (11.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.6.12) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.6.12) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.6.12) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.6.12) (2024.8.30)\n","Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: timm\n","  Attempting uninstall: timm\n","    Found existing installation: timm 1.0.11\n","    Uninstalling timm-1.0.11:\n","      Successfully uninstalled timm-1.0.11\n","Successfully installed timm-0.6.12\n","Collecting torcheval==0.0.7\n","  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval==0.0.7) (4.12.2)\n","Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torcheval\n","Successfully installed torcheval-0.0.7\n","Collecting wandb==0.15.4\n","  Downloading wandb-0.15.4-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.4) (8.1.7)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.4) (3.1.43)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.4) (2.32.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.4) (5.9.5)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.4) (2.18.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.4) (0.4.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.4) (6.0)\n","Collecting pathtools (from wandb==0.15.4)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.4) (1.3.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.4) (75.1.0)\n","Collecting appdirs>=1.4.3 (from wandb==0.15.4)\n","  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.4) (4.25.5)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb==0.15.4) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.15.4) (4.0.11)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.15.4) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.15.4) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.15.4) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.15.4) (2024.8.30)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.15.4) (5.0.1)\n","Downloading wandb-0.15.4-py3-none-any.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8793 sha256=727757b1562ec77baa838c667e2a0f607eb2b32b588a8a7c18f0e2ef9c3427e6\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built pathtools\n","Installing collected packages: pathtools, appdirs, wandb\n","  Attempting uninstall: wandb\n","    Found existing installation: wandb 0.18.7\n","    Uninstalling wandb-0.18.7:\n","      Successfully uninstalled wandb-0.18.7\n","Successfully installed appdirs-1.4.4 pathtools-0.1.2 wandb-0.15.4\n","Collecting lightning_utilities==0.9.0\n","  Downloading lightning_utilities-0.9.0-py3-none-any.whl.metadata (4.6 kB)\n","Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning_utilities==0.9.0) (24.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning_utilities==0.9.0) (4.12.2)\n","Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n","Installing collected packages: lightning_utilities\n","  Attempting uninstall: lightning_utilities\n","    Found existing installation: lightning-utilities 0.11.9\n","    Uninstalling lightning-utilities-0.11.9:\n","      Successfully uninstalled lightning-utilities-0.11.9\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchmetrics 1.6.0 requires torch>=2.0.0, but you have torch 1.12.1+cu116 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed lightning_utilities-0.9.0\n","Collecting umap_learn==0.5.4\n","  Downloading umap-learn-0.5.4.tar.gz (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.8/90.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap_learn==0.5.4) (1.24.4)\n","Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap_learn==0.5.4) (1.8.1)\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap_learn==0.5.4) (1.3.2)\n","Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap_learn==0.5.4) (0.60.0)\n","Collecting pynndescent>=0.5 (from umap_learn==0.5.4)\n","  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap_learn==0.5.4) (4.66.6)\n","Requirement already satisfied: tbb>=2019.0 in /usr/local/lib/python3.10/dist-packages (from umap_learn==0.5.4) (2022.0.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap_learn==0.5.4) (0.43.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap_learn==0.5.4) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap_learn==0.5.4) (3.5.0)\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb>=2019.0->umap_learn==0.5.4) (1.2.0)\n","Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: umap_learn\n","  Building wheel for umap_learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap_learn: filename=umap_learn-0.5.4-py3-none-any.whl size=86775 sha256=e62bb02fdd015d600b1b368ae80b93418858c69f81a4db6d672255f0df21562f\n","  Stored in directory: /root/.cache/pip/wheels/fb/66/29/199acf5784d0f7b8add6d466175ab45506c96e386ed5dd0633\n","Successfully built umap_learn\n","Installing collected packages: pynndescent, umap_learn\n","Successfully installed pynndescent-0.5.13 umap_learn-0.5.4\n","Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.2)\n","Collecting comet_ml\n","  Downloading comet_ml-3.47.3-py3-none-any.whl.metadata (3.9 kB)\n","Collecting everett<3.2.0,>=1.0.1 (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n","  Downloading everett-3.1.0-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (4.23.0)\n","Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (5.9.5)\n","Collecting python-box<7.0.0 (from comet_ml)\n","  Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.8 kB)\n","Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.0.0)\n","Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.32.3)\n","Collecting semantic-version>=2.8.0 (from comet_ml)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.18.0)\n","Collecting simplejson (from comet_ml)\n","  Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n","Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.2.3)\n","Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.16.0)\n","Collecting wurlitzer>=1.0.2 (from comet_ml)\n","  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n","Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml)\n","  Downloading dulwich-0.22.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n","Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (13.9.4)\n","Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n","  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.21.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (2024.8.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (2.18.0)\n","Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (4.12.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n","Downloading comet_ml-3.47.3-py3-none-any.whl (709 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.7/709.7 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dulwich-0.22.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (981 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.8/981.8 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n","Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n","Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n","Installing collected packages: everett, wurlitzer, simplejson, semantic-version, python-box, dulwich, configobj, comet_ml\n","  Attempting uninstall: python-box\n","    Found existing installation: python-box 7.2.0\n","    Uninstalling python-box-7.2.0:\n","      Successfully uninstalled python-box-7.2.0\n","Successfully installed comet_ml-3.47.3 configobj-5.0.9 dulwich-0.22.6 everett-3.1.0 python-box-6.1.0 semantic-version-2.10.0 simplejson-3.19.3 wurlitzer-3.1.1\n"]}],"source":["!pip install albumentations==1.2.1\n","!pip install matplotlib==3.7.3\n","!pip install numpy==1.22.4\n","!pip install pandas==1.4.3\n","!pip install pytorch_lightning==1.9.5\n","!pip install pyyaml==6.0\n","!pip install scikit_image==0.19.3\n","!pip install scikit_learn==1.3.2\n","!pip install scipy==1.8.1\n","!pip install torch==1.12.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n","!pip install torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n","!pip install torchaudio==0.12.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n","!pip install opencv_contrib_python==4.4.0.46\n","!pip install seaborn==0.13.0\n","!pip install timm==0.6.12\n","!pip install torcheval==0.0.7\n","!pip install wandb==0.15.4\n","!pip install lightning_utilities==0.9.0\n","!pip install umap_learn==0.5.4\n","!pip install plotly\n","!pip install comet_ml\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JJM_0QVITdZX"},"outputs":[],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34060,"status":"ok","timestamp":1732702146030,"user":{"displayName":"Rojen Arda Şeşen","userId":"09468982930633953911"},"user_tz":-180},"id":"giz7jXWET3O4","outputId":"d5083cdb-f760-40bb-92e8-5bcaedf2bb23"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"soBdi30ETDxm"},"source":["# CoReEcho Training and Evaluation"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29034,"status":"ok","timestamp":1732702234244,"user":{"displayName":"Rojen Arda Şeşen","userId":"09468982930633953911"},"user_tz":-180},"id":"JSvJov9hTDxq","outputId":"ed18accd-c5eb-4757-f2dc-a886c8013b17"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["from comet_ml import Experiment\n","\n","import argparse\n","import os\n","import sys\n","import logging\n","import torch\n","import time\n","import copy\n","import pandas as pd\n","import pickle\n","\n","from torcheval.metrics.functional import r2_score\n","\n","from coreecho import get_feature_extractor\n","from coreecho.dataloader import set_loader\n","from coreecho.loss import RnCLoss\n","from coreecho.regressor import get_shallow_mlp_head\n","from coreecho.utils import AverageMeter, load_model, save_model, set_seed, set_optimizer\n","from coreecho.validation import validate\n","from coreecho.viz import HelperTSNE, HelperUMAP\n","from coreecho.dataset import EchoNetTest\n","\n","\n","ECHO_FILE_ROOT = os.path.join('drive', 'MyDrive', 'echo')\n","ECHONET_DYNAMIC_DATA_DIR = os.path.join(ECHO_FILE_ROOT, 'EchoNet-Dynamic')\n","UNIFORMER_WEIGHTS_DIR = os.path.join(ECHO_FILE_ROOT, 'models', 'uniformer_small_k400_16x8.pth')\n","COMET_API_KEY = ''\n","MODEL_PATH = os.path.join(ECHO_FILE_ROOT, 'models', 'coreecho')\n"]},{"cell_type":"markdown","metadata":{"id":"gAWFmgmOTDxr"},"source":["## Helper Functions"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":457,"status":"ok","timestamp":1732702316138,"user":{"displayName":"Rojen Arda Şeşen","userId":"09468982930633953911"},"user_tz":-180},"id":"IZcZGnPtTDxs"},"outputs":[],"source":["def adjust_learning_rate(args, optimizer, epoch):\n","    lr = args.learning_rate\n","\n","    eta_min = lr * args.lr_decay_rate\n","\n","    if args.lr_step_epoch != -1:\n","        if epoch >= args.lr_step_epoch:\n","            lr = eta_min\n","\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","    return lr\n","\n","print = logging.info"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1732702317210,"user":{"displayName":"Rojen Arda Şeşen","userId":"09468982930633953911"},"user_tz":-180},"id":"fnDkMn14TDxs"},"outputs":[],"source":["def parse_option(custom_args=None, stage: int = 1):\n","    assert stage in [1, 2, 3], \"Invalid stage\"\n","    parser = argparse.ArgumentParser('argument for training')\n","\n","    parser.add_argument('--print_freq', type=int, default=10, help='print frequency')\n","    parser.add_argument('--batch_size', type=int, default=256, help='batch_size')\n","    parser.add_argument('--num_workers', type=int, default=16, help='num of workers to use')\n","    parser.add_argument('--epochs', type=int, default=400, help='number of training epochs')\n","    parser.add_argument('--learning_rate', type=float, default=0.5, help='learning rate')\n","    parser.add_argument('--lr_decay_rate', type=float, default=0.1, help='decay rate for learning rate')\n","    parser.add_argument('--lr_step_epoch', type=int, default=15)\n","    parser.add_argument('--weight_decay', type=float, default=1e-4, help='weight decay')\n","    parser.add_argument('--val_n_clips_per_sample', type=int, default=1)\n","    parser.add_argument('--trial', type=int if stage == 1 else str, default=0 if stage == 1 else '0', help='id for recording multiple runs')\n","    parser.add_argument('--data_folder', type=str, default='./data', help='path to custom dataset')\n","    parser.add_argument('--model', type=str, default='uniformer_small', choices=['uniformer_small'])\n","    parser.add_argument('--aug', action='store_true', help='whether to use augmentations')\n","    parser.add_argument('--temp', type=float, default=2, help='temperature')\n","    parser.add_argument('--label_diff', type=str, default='l1', choices=['l1'], help='label distance function')\n","    parser.add_argument('--feature_sim', type=str, default='l2', choices=['l2'], help='feature similarity function')\n","    parser.add_argument('--frames', type=int)\n","    parser.add_argument('--frequency', type=int)\n","    parser.add_argument('--pretrained_weights', type=str, default=None)\n","    parser.add_argument('--project_name', type=str, default='coreecho')\n","    parser.add_argument('--model_path', type=str, default=MODEL_PATH)\n","    parser.add_argument('--path_test_start_indexes', type=str, default=None)\n","    parser.add_argument('--path_save_test_files', type=str, default=None)\n","    if custom_args:\n","        opt = parser.parse_args(custom_args)\n","    else:\n","        opt = parser.parse_args()\n","\n","    opt.optim = 'adamw'\n","\n","    if stage == 1:\n","        opt.model_name = 'RnC+L1SG_{}_ep_{}_lr_{}_d_{}_wd_{}_bsz_{}_aug_{}_temp_{}_label_{}_feature_{}_trial_{}'. \\\n","            format(\n","                opt.model, opt.epochs, opt.learning_rate, opt.lr_decay_rate, opt.weight_decay,\n","                opt.batch_size, opt.aug, opt.temp, opt.label_diff, opt.feature_sim, opt.trial\n","            )\n","    elif stage == 2 or stage == 3:\n","        opt.model_name = 'RnC (LP)_{}_ep_{}__d_{}_wd_{}_bsz_{}_aug_{}_temp_{}_label_{}_feature_{}_trial_{}'. \\\n","            format(\n","                opt.model, opt.epochs, opt.learning_rate, opt.weight_decay, opt.batch_size,\n","                opt.aug, opt.temp, opt.label_diff, opt.feature_sim, opt.trial\n","            )\n","    else:\n","        raise ValueError(\"Invalid stage\")\n","\n","    opt.save_folder = os.path.join(opt.model_path, opt.model_name)\n","    if not os.path.isdir(opt.save_folder):\n","        os.makedirs(opt.save_folder)\n","    else:\n","        print('WARNING: folder exist.')\n","\n","    logging.root.handlers = []\n","    logging.basicConfig(\n","        level=logging.INFO,\n","        format=\"%(asctime)s | %(message)s\",\n","        handlers=[\n","            logging.FileHandler(os.path.join(opt.save_folder, 'training.log')),\n","            logging.StreamHandler()\n","        ])\n","\n","    print(f\"Model name: {opt.model_name}\")\n","    print(f\"Options: {opt}\")\n","\n","    return opt"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1732702317210,"user":{"displayName":"Rojen Arda Şeşen","userId":"09468982930633953911"},"user_tz":-180},"id":"ufwfwu7kTDxt"},"outputs":[],"source":["def set_model(opt, stage: int = 1):\n","    assert stage in [1, 2, 3], \"Invalid stage\"\n","    model = get_feature_extractor(opt.model, opt.pretrained_weights if stage == 1 else None)\n","    if opt.model == 'uniformer_small':\n","        dim_in = model.head.in_features\n","    else:\n","        dim_in = model.fc.in_features\n","    dim_out = 1\n","\n","    regressor = get_shallow_mlp_head(dim_in, dim_out)\n","\n","    if stage == 1:\n","        criterion = RnCLoss(temperature=opt.temp, label_diff=opt.label_diff, feature_sim=opt.feature_sim)\n","    else:\n","        checkpoint = torch.load(opt.pretrained_weights, map_location='cpu')\n","        model = load_model(model, checkpoint['model'])\n","        regressor = load_model(regressor, checkpoint['regressor'])\n","\n","\n","    if torch.cuda.is_available():\n","        if torch.cuda.device_count() > 1:\n","            model = torch.nn.DataParallel(model)\n","            regressor = torch.nn.DataParallel(regressor)\n","        model = model.cuda()\n","        regressor = regressor.cuda()\n","        if stage == 1:\n","            criterion = criterion.cuda()\n","        torch.backends.cudnn.benchmark = True\n","\n","    if stage == 1:\n","        return model, criterion, regressor\n","    else:\n","        return model, regressor"]},{"cell_type":"markdown","metadata":{"id":"__PpZrijTDxu"},"source":["## First Stage Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E8z-k4i0TDxu"},"outputs":[],"source":["def train(train_loader, model, criterion, optimizer, epoch, opt, regressor, optimizer_regressor):\n","    model.train()\n","    regressor.train()\n","\n","    criterion_mse = torch.nn.L1Loss()\n","\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","\n","    end = time.time()\n","    for idx, batch in enumerate(train_loader):\n","        data_time.update(time.time() - end)\n","\n","        views1, views2 = batch\n","        images = torch.cat([views1[\"image\"], views2[\"image\"]], dim=0)\n","        labels = views1[\"label\"]\n","        bsz = labels.shape[0]\n","\n","        if torch.cuda.is_available():\n","            images = images.cuda(non_blocking=True)\n","            labels = labels.cuda(non_blocking=True)\n","\n","        _, features = model(images)\n","        f1, f2 = torch.split(features, [bsz, bsz], dim=0)\n","        features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1)\n","\n","        loss = criterion(features, labels)\n","        losses.update(loss.item(), bsz)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        features = features.detach()\n","        y_preds = regressor(torch.cat((features[:,0], features[:,1]), dim=0))\n","        loss_reg = criterion_mse(y_preds, labels.repeat(2, 1))\n","\n","        optimizer_regressor.zero_grad()\n","        loss_reg.backward()\n","        optimizer_regressor.step()\n","\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if (idx + 1) % opt.print_freq == 0:\n","            to_print = 'Train: [{0}][{1}/{2}]\\t' \\\n","                        'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' \\\n","                        'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t' \\\n","                        'loss {loss.val:.5f} ({loss.avg:.5f})'.format(\n","                epoch, idx + 1, len(train_loader), batch_time=batch_time,\n","                data_time=data_time, loss=losses\n","            )\n","            print(to_print)\n","            sys.stdout.flush()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1eikF0fplY2LZ61tsaL-SjGzG2_nzSJuN"},"executionInfo":{"elapsed":16486729,"status":"ok","timestamp":1732663721819,"user":{"displayName":"Rojen Arda Şeşen","userId":"09468982930633953911"},"user_tz":-180},"id":"mbtbTETcTDxv","outputId":"c47933bb-87ed-40c8-c898-485f55a9771c"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["stage_1_args = [\n","    '--data_folder', ECHONET_DYNAMIC_DATA_DIR,\n","    '--pretrained_weights', UNIFORMER_WEIGHTS_DIR,\n","    '--project_name', 'coreecho-training-stage-1',\n","    '--model', 'uniformer_small',\n","    '--num_workers', '8',\n","    '--batch_size', '16',\n","    '--frames', '36',\n","    '--frequency', '4',\n","    '--learning_rate', '1e-4',\n","    '--weight_decay', '1e-4',\n","    '--lr_decay_rate', '0.1',\n","    '--val_n_clips_per_sample', '3',\n","    '--temp', '1.0',\n","    '--aug',\n","    '--epochs', '25',\n","    '--trial', '0',\n","    '--model_path', MODEL_PATH\n","]\n","\n","opt = parse_option(stage_1_args)\n","\n","\n","# Initialize Comet Experiment\n","experiment = Experiment(\n","    api_key=COMET_API_KEY,\n","    project_name=opt.project_name\n",")\n","\n","# Set experiment parameters\n","experiment.set_name(opt.model_name)\n","experiment.log_parameters(vars(opt))\n","\n","# Set seed (for reproducibility)\n","set_seed(opt.trial)\n","\n","# build data loader\n","train_loader, train_no_aug_loader, val_loader, test_loader = set_loader(opt)\n","\n","# build model and criterion\n","model, criterion, regressor = set_model(opt)\n","\n","# build optimizer\n","optimizer = set_optimizer(opt, model)\n","optimizer_regressor = set_optimizer(opt, regressor)\n","\n","start_epoch = 0\n","\n","# training routine\n","best_error = 1e5\n","save_file_best = os.path.join(opt.save_folder, 'best.pth')\n","for epoch in range(start_epoch, opt.epochs + 1):\n","    lr_cur_val = adjust_learning_rate(opt, optimizer, epoch)\n","    _ = adjust_learning_rate(opt, optimizer_regressor, epoch)\n","\n","    train(train_loader, model, criterion, optimizer, epoch, opt, regressor, optimizer_regressor)\n","\n","    valid_metrics, valid_aux  = validate(val_loader, model, regressor, opt.val_n_clips_per_sample)\n","    valid_tsne = HelperTSNE(valid_aux['embeddings'], n_components=2, perplexity=5, random_state=7)\n","    valid_umap = HelperUMAP(valid_aux['embeddings'], n_components=2, n_neighbors=5, init='random', random_state=0)\n","\n","    valid_error = valid_metrics['l1']\n","    is_best = valid_error <= best_error\n","    best_error = min(valid_error, best_error)\n","    print(f\"Best MAE: {best_error:.3f}\")\n","\n","    if is_best:\n","        torch.save({\n","            'epoch': epoch,\n","            'model': model.state_dict(),\n","            'regressor': regressor.state_dict(),\n","            'best_error': best_error,\n","        }, save_file_best)\n","\n","    experiment.log_metric(\"epoch\", epoch)\n","    experiment.log_metric(\"learning_rate\", lr_cur_val)\n","    experiment.log_metric(\"Val R2\", valid_metrics['r2'].item())\n","    experiment.log_metric(\"Val L2\", valid_metrics['l2'].item())\n","    experiment.log_metric(\"Val L1\", valid_metrics['l1'].item())\n","    for key, val in valid_aux['aux'].items():\n","        experiment.log_figure(f\"Val UMAP ({key})\", valid_umap(val))\n","        experiment.log_figure(f\"Val TSNE ({key})\", valid_tsne(val))\n","\n","    save_file = os.path.join(opt.save_folder, 'last.pth')\n","    save_model(model, regressor, opt, epoch, save_file, best_error)\n","\n","\n","experiment.end()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":264555,"status":"ok","timestamp":1732664163852,"user":{"displayName":"Rojen Arda Şeşen","userId":"09468982930633953911"},"user_tz":-180},"id":"W4fPkTnYtKZN","outputId":"1e8600ea-7428-4702-ef72-c1ff8e15a7e9"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-11-26 23:31:39,256 | ========================================================================================================================\n","2024-11-26 23:31:39,258 | Test best model on test set...\n","2024-11-26 23:31:39,438 | Loaded best model, epoch 16, best val error 3.776\n","2024-11-26 23:32:57,933 | Test R2: 0.822\n","2024-11-26 23:32:57,935 | Test L2: 5.153\n","2024-11-26 23:32:57,937 | Test L1: 3.901\n","2024-11-26 23:34:00,922 | Val R2: 0.837\n","2024-11-26 23:34:00,924 | Val L2: 4.967\n","2024-11-26 23:34:00,927 | Val L1: 3.796\n","2024-11-26 23:36:03,499 | Train R2: 0.931\n","2024-11-26 23:36:03,501 | Train L2: 3.259\n","2024-11-26 23:36:03,503 | Train L1: 2.489\n"]}],"source":["print(\"=\" * 120)\n","print(\"Test best model on test set...\")\n","checkpoint = torch.load(save_file_best)\n","model.load_state_dict(checkpoint['model'])\n","regressor.load_state_dict(checkpoint['regressor'])\n","print(f\"Loaded best model, epoch {checkpoint['epoch']}, best val error {checkpoint['best_error']:.3f}\")\n","\n","set_seed(opt.trial)\n","test_metrics, test_aux = validate(test_loader, model, regressor, opt.val_n_clips_per_sample)\n","print('Test R2: {:.3f}'.format(test_metrics['r2']))\n","print('Test L2: {:.3f}'.format(test_metrics['l2']))\n","print('Test L1: {:.3f}'.format(test_metrics['l1']))\n","\n","set_seed(opt.trial)\n","val_metrics, val_aux = validate(val_loader, model, regressor, opt.val_n_clips_per_sample)\n","print('Val R2: {:.3f}'.format(val_metrics['r2']))\n","print('Val L2: {:.3f}'.format(val_metrics['l2']))\n","print('Val L1: {:.3f}'.format(val_metrics['l1']))\n","\n","set_seed(opt.trial)\n","train_metrics, train_aux = validate(train_no_aug_loader, model, regressor)\n","print('Train R2: {:.3f}'.format(train_metrics['r2']))\n","print('Train L2: {:.3f}'.format(train_metrics['l2']))\n","print('Train L1: {:.3f}'.format(train_metrics['l1']))\n","\n","# train_tsne = HelperTSNE(train_aux['embeddings'], n_components=2, perplexity=5, random_state=7)\n","# train_umap = HelperUMAP(train_aux['embeddings'], n_components=2, n_neighbors=5, init='random', random_state=0)\n","\n","# val_tsne = HelperTSNE(val_aux['embeddings'], n_components=2, perplexity=5, random_state=7)\n","# val_umap = HelperUMAP(val_aux['embeddings'], n_components=2, n_neighbors=5, init='random', random_state=0)\n","\n","# test_tsne = HelperTSNE(test_aux['embeddings'], n_components=2, perplexity=5, random_state=7)\n","# test_umap = HelperUMAP(test_aux['embeddings'], n_components=2, n_neighbors=5, init='random', random_state=0)\n"]},{"cell_type":"markdown","metadata":{"id":"3oxj_DAMTDxw"},"source":["## Second Stage Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T8OFJheYTDxw"},"outputs":[],"source":["def train_lp(train_loader, model, epoch, opt, regressor, optimizer_regressor):\n","    model.eval()\n","    regressor.train()\n","\n","    criterion_mse = torch.nn.L1Loss()\n","\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","\n","    end = time.time()\n","    for idx, batch in enumerate(train_loader):\n","        data_time.update(time.time() - end)\n","\n","        views1, _ = batch\n","        images = views1[\"image\"]\n","        labels = views1[\"label\"]\n","\n","        if torch.cuda.is_available():\n","            images = images.cuda(non_blocking=True)\n","            labels = labels.cuda(non_blocking=True)\n","\n","        with torch.no_grad():\n","            _, features = model(images)\n","        features = features.detach()\n","        y_preds = regressor(features)\n","        loss_reg = criterion_mse(y_preds, labels)\n","\n","        optimizer_regressor.zero_grad()\n","        loss_reg.backward()\n","        optimizer_regressor.step()\n","\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if (idx + 1) % opt.print_freq == 0:\n","            to_print = 'Train: [{0}][{1}/{2}]\\t' \\\n","                        'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' \\\n","                        'DT {data_time.val:.3f} ({data_time.avg:.3f})'.format(\n","                epoch, idx + 1, len(train_loader), batch_time=batch_time,\n","                data_time=data_time\n","            )\n","            print(to_print)\n","            sys.stdout.flush()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1250d5Iq0uGC-RSMZrgVCPYRZKMkalhv6"},"collapsed":true,"executionInfo":{"elapsed":1352869,"status":"ok","timestamp":1732665543426,"user":{"displayName":"Rojen Arda Şeşen","userId":"09468982930633953911"},"user_tz":-180},"id":"dzTlnWMcTDxw","outputId":"1593f777-e06d-4e93-9022-8a29c25ee3bd"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["stage_2_args = [\n","    '--data_folder', ECHONET_DYNAMIC_DATA_DIR,\n","    '--pretrained_weights', save_file_best,\n","    '--project_name', 'coreeecho-training-stage-2',\n","    '--model', 'uniformer_small',\n","    '--num_workers', '8',\n","    '--batch_size', '16',\n","    '--frames', '36',\n","    '--frequency', '4',\n","    '--learning_rate', '1e-4',\n","    '--weight_decay', '1e-4',\n","    '--val_n_clips_per_sample', '3',\n","    '--aug',\n","    '--epochs', '4',\n","    '--trial', '0',\n","    '--model_path', MODEL_PATH\n","]\n","\n","\n","opt = parse_option(stage_2_args, stage=2)\n","\n","# Initialize Comet Experiment\n","experiment = Experiment(\n","    api_key=COMET_API_KEY,\n","    project_name=opt.project_name,\n",")\n","\n","# Set experiment parameters\n","experiment.set_name(opt.model_name)\n","experiment.log_parameters(vars(opt))\n","\n","\n","# Set seed (for reproducibility)\n","set_seed(opt.trial)\n","\n","# build data loader\n","train_loader, train_no_aug_loader, val_loader, test_loader = set_loader(opt)\n","\n","# build model and criterion\n","model, regressor = set_model(opt, stage=2)\n","\n","# build optimizer\n","optimizer_regressor = set_optimizer(opt, regressor)\n","\n","start_epoch = 0\n","\n","# training routine\n","best_error = 1e5\n","save_file_best = os.path.join(opt.save_folder, 'best.pth')\n","for epoch in range(start_epoch, opt.epochs + 1):\n","    lr_cur_val = opt.learning_rate\n","\n","    train_lp(train_loader, model, epoch, opt, regressor, optimizer_regressor)\n","\n","    valid_metrics, valid_aux  = validate(val_loader, model, regressor, opt.val_n_clips_per_sample)\n","    valid_tsne = HelperTSNE(valid_aux['embeddings'], n_components=2, perplexity=5, random_state=7)\n","    valid_umap = HelperUMAP(valid_aux['embeddings'], n_components=2, n_neighbors=5, init='random', random_state=0)\n","\n","    valid_error = valid_metrics['l1']\n","    is_best = valid_error <= best_error\n","    best_error = min(valid_error, best_error)\n","    print(f\"Best MAE: {best_error:.3f}\")\n","\n","    if is_best:\n","        torch.save({\n","            'epoch': epoch,\n","            'model': model.state_dict(),\n","            'regressor': regressor.state_dict(),\n","            'best_error': best_error,\n","        }, save_file_best)\n","\n","\n","    experiment.log_metric(\"epoch\", epoch)\n","    experiment.log_metric(\"learning_rate\", lr_cur_val)\n","    experiment.log_metric(\"Val R2\", valid_metrics['r2'].item())\n","    experiment.log_metric(\"Val L2\", valid_metrics['l2'].item())\n","    experiment.log_metric(\"Val L1\", valid_metrics['l1'].item())\n","    for key, val in valid_aux['aux'].items():\n","        experiment.log_figure(f\"Val UMAP ({key})\", valid_umap(val))\n","        experiment.log_figure(f\"Val TSNE ({key})\", valid_tsne(val))\n","\n","\n","    save_file = os.path.join(opt.save_folder, 'last.pth')\n","    save_model(model, regressor, opt, epoch, save_file)\n","\n","experiment.end()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SaPuxZq3AI4L"},"outputs":[],"source":["print(\"=\" * 120)\n","print(\"Test best model on test set...\")\n","checkpoint = torch.load(save_file_best)\n","model.load_state_dict(checkpoint['model'])\n","regressor.load_state_dict(checkpoint['regressor'])\n","print(f\"Loaded best model, epoch {checkpoint['epoch']}, best val error {checkpoint['best_error']:.3f}\")\n","\n","set_seed(opt.trial)\n","test_metrics, test_aux = validate(test_loader, model, regressor, opt.val_n_clips_per_sample)\n","print('Test R2: {:.3f}'.format(test_metrics['r2']))\n","print('Test L2: {:.3f}'.format(test_metrics['l2']))\n","print('Test L1: {:.3f}'.format(test_metrics['l1']))\n","\n","set_seed(opt.trial)\n","val_metrics, val_aux = validate(val_loader, model, regressor, opt.val_n_clips_per_sample)\n","print('Val R2: {:.3f}'.format(val_metrics['r2']))\n","print('Val L2: {:.3f}'.format(val_metrics['l2']))\n","print('Val L1: {:.3f}'.format(val_metrics['l1']))\n","\n","set_seed(opt.trial)\n","train_metrics, train_aux = validate(train_no_aug_loader, model, regressor)\n","print('Train R2: {:.3f}'.format(train_metrics['r2']))\n","print('Train L2: {:.3f}'.format(train_metrics['l2']))\n","print('Train L1: {:.3f}'.format(train_metrics['l1']))\n","\n","# train_tsne = HelperTSNE(train_aux['embeddings'], n_components=2, perplexity=5, random_state=7)\n","# train_umap = HelperUMAP(train_aux['embeddings'], n_components=2, n_neighbors=5, init='random', random_state=0)\n","\n","# val_tsne = HelperTSNE(val_aux['embeddings'], n_components=2, perplexity=5, random_state=7)\n","# val_umap = HelperUMAP(val_aux['embeddings'], n_components=2, n_neighbors=5, init='random', random_state=0)\n","\n","# test_tsne = HelperTSNE(test_aux['embeddings'], n_components=2, perplexity=5, random_state=7)\n","# test_umap = HelperUMAP(test_aux['embeddings'], n_components=2, n_neighbors=5, init='random', random_state=0)"]},{"cell_type":"markdown","metadata":{"id":"HRcFL4BuTDxw"},"source":["## Test Stage"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":474,"status":"ok","timestamp":1732702350124,"user":{"displayName":"Rojen Arda Şeşen","userId":"09468982930633953911"},"user_tz":-180},"id":"SrBo8LyYN0YO"},"outputs":[],"source":["def set_test_loader(opt):\n","    test_ds = EchoNetTest(\n","            root=opt.data_folder,\n","            frames=opt.frames,\n","            frequency=opt.frequency,\n","            path_test_start_indexes=opt.path_test_start_indexes,\n","            trial=opt.trial,\n","    )\n","\n","    test_loader = torch.utils.data.DataLoader(\n","        test_ds, batch_size=1, shuffle=False, num_workers=opt.num_workers,\n","    )\n","\n","    return test_loader"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":512,"status":"ok","timestamp":1732702295293,"user":{"displayName":"Rojen Arda Şeşen","userId":"09468982930633953911"},"user_tz":-180},"id":"6LvVNPLJOzfs"},"outputs":[],"source":["save_file_best = '/content/drive/MyDrive/echo/models/coreecho/RnC (LP)_uniformer_small_ep_4__d_0.0001_wd_0.0001_bsz_16_aug_True_temp_2_label_l1_feature_l2_trial_0/best.pth'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LcsC7HtfTDxx","outputId":"d7bc6ca4-291e-4b16-a32e-5d837b2f3a35"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-11-27 10:12:44,202 | WARNING: folder exist.\n","2024-11-27 10:12:44,207 | Model name: RnC (LP)_uniformer_small_ep_400__d_0.5_wd_0.0001_bsz_256_aug_False_temp_2_label_l1_feature_l2_trial_0\n","2024-11-27 10:12:44,209 | Options: Namespace(print_freq=10, batch_size=256, num_workers=4, epochs=400, learning_rate=0.5, lr_decay_rate=0.1, lr_step_epoch=15, weight_decay=0.0001, val_n_clips_per_sample=1, trial='0', data_folder='drive/MyDrive/echo/EchoNet-Dynamic', model='uniformer_small', aug=False, temp=2, label_diff='l1', feature_sim='l2', frames=36, frequency=4, pretrained_weights='/content/drive/MyDrive/echo/models/coreecho/RnC (LP)_uniformer_small_ep_4__d_0.0001_wd_0.0001_bsz_16_aug_True_temp_2_label_l1_feature_l2_trial_0/best.pth', project_name='coreecho-test', model_path='drive/MyDrive/echo/models/coreecho', path_test_start_indexes='./test_start_indexes.pkl', path_save_test_files='drive/MyDrive/echo/coreecho/test_files', optim='adamw', model_name='RnC (LP)_uniformer_small_ep_400__d_0.5_wd_0.0001_bsz_256_aug_False_temp_2_label_l1_feature_l2_trial_0', save_folder='drive/MyDrive/echo/models/coreecho/RnC (LP)_uniformer_small_ep_400__d_0.5_wd_0.0001_bsz_256_aug_False_temp_2_label_l1_feature_l2_trial_0')\n","\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Couldn't retrieve and log Google Colab notebook content, reason: 'NoneType' object is not subscriptable\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : RnC (LP)_uniformer_small_ep_400__d_0.5_wd_0.0001_bsz_256_aug_False_temp_2_label_l1_feature_l2_trial_0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/rojenarda/coreecho-test/13bb311d853c4c7698f4e29033ef7187\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name         : RnC (LP)_uniformer_small_ep_400__d_0.5_wd_0.0001_bsz_256_aug_False_temp_2_label_l1_feature_l2_trial_0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook_url : https://colab.research.google.com/notebook#fileId=1W_7V113a_uWyaE2CJ4TqksRa_UyEqI-T\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     aug                     : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size              : 256\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data_folder             : drive/MyDrive/echo/EchoNet-Dynamic\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs                  : 400\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     feature_sim             : l2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     frames                  : 36\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     frequency               : 4\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_diff              : l1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     learning_rate           : 0.5\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr_decay_rate           : 0.1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr_step_epoch           : 15\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model                   : uniformer_small\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_name              : RnC (LP)_uniformer_small_ep_400__d_0.5_wd_0.0001_bsz_256_aug_False_temp_2_label_l1_feature_l2_trial_0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_path              : drive/MyDrive/echo/models/coreecho\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_workers             : 4\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optim                   : adamw\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     path_save_test_files    : drive/MyDrive/echo/coreecho/test_files\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     path_test_start_indexes : ./test_start_indexes.pkl\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained_weights      : /content/drive/MyDrive/echo/models/coreecho/RnC (LP)_uniformer_small_ep_4__d_0.0001_wd_0.0001_bsz_16_aug_True_temp_2_label_l1_feature_l2_trial_0/best.pth\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     print_freq              : 10\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project_name            : coreecho-test\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_folder             : drive/MyDrive/echo/models/coreecho/RnC (LP)_uniformer_small_ep_400__d_0.5_wd_0.0001_bsz_256_aug_False_temp_2_label_l1_feature_l2_trial_0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     temp                    : 2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trial                   : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_n_clips_per_sample  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay            : 0.0001\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n","\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/rojenarda/coreecho-test/49d618ca4a064fe6af234c9b98b9b1d8\n","\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"]},{"name":"stdout","output_type":"stream","text":["test dataset size: 1276\n"]}],"source":["test_args = [\n","'--data_folder', ECHONET_DYNAMIC_DATA_DIR,\n","'--pretrained_weights', save_file_best ,\n","'--path_test_start_indexes', './test_start_indexes.pkl' ,\n","'--path_save_test_files', os.path.join(ECHO_FILE_ROOT, 'coreecho', 'test_files'),\n","'--model', 'uniformer_small',\n","'--frames', '36',\n","'--frequency', '4',\n","'--num_workers', '4',\n","'--project_name', 'coreecho-test',\n","]\n","\n","opt = parse_option(test_args, stage=3)\n","\n","if not os.path.exists(opt.path_save_test_files):\n","    os.makedirs(opt.path_save_test_files)\n","\n","experiment = Experiment(\n","    api_key=COMET_API_KEY,\n","    project_name=opt.project_name,\n",")\n","\n","# Set experiment parameters\n","experiment.set_name(opt.model_name)\n","experiment.log_parameters(vars(opt))\n","\n","model, regressor = set_model(opt, stage=3)\n","\n","df = pd.read_pickle(opt.path_test_start_indexes)\n","list_trial = list(range(len(df[list(df.keys())[0]])))\n","\n","list_outputs = []\n","best_r2 = -1_000_000\n","for trial in list_trial:\n","    opt.trial = trial\n","    test_loader = set_test_loader(opt)\n","    test_metrics, test_aux = validate(test_loader, model, regressor)\n","    if best_r2 <= test_metrics['r2']:\n","        best_r2 = max(best_r2, test_metrics['r2'])\n","        best_metrics = copy.deepcopy(test_metrics)\n","        best_aux = copy.deepcopy(test_aux)\n","    list_outputs.append(test_aux['outputs'])\n","\n","    print('-'*10)\n","    print('Trial ', trial)\n","    print(test_metrics)\n","    print('')\n","\n","outputs = torch.cat(list_outputs, dim=1).mean(dim=1)[:,None]\n","labels = test_aux['labels']\n","\n","metrics = {\n","    'r2': r2_score(outputs, labels),\n","    'l1': torch.nn.L1Loss()(outputs, labels),\n","    'l2': torch.sqrt(torch.nn.MSELoss()(outputs, labels)),\n","}\n","\n","experiment.log_metrics(metrics)\n","\n","\n","print('-'*30)\n","print(f'Metrics from {len(list_trial)}x clips')\n","print(metrics)\n","\n","dict_test_files = {\n","    'N clips': len(list_trial),\n","    'metrics xN clips': metrics,\n","    'best_metrics x1 clip': best_metrics,\n","    'best_aux x1 clip': best_aux,\n","}\n","\n","with open(opt.path_save_test_files, 'wb') as f:\n","    pickle.dump(dict_test_files, f)\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["gAWFmgmOTDxr","__PpZrijTDxu","3oxj_DAMTDxw"],"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"ml-TZuhtEye","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
